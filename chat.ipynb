{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import Config, RepositoryEnv\n",
    "from anthropic import Anthropic\n",
    "\n",
    "DOTENV_FILE = '.env'\n",
    "cfg = Config(RepositoryEnv(DOTENV_FILE))\n",
    "anthropic_key = cfg('ANTHROPIC_KEY')\n",
    "anthropic_client = Anthropic(\n",
    "    api_key= anthropic_key,\n",
    ")\n",
    "\n",
    "claude_haiku = 'claude-3-haiku-20240307'\n",
    "claude_opus = 'claude-3-opus-20240229'\n",
    "claude_sonnet = 'claude-3-sonnet-20240229'\n",
    "\n",
    "def claude_stream(*, model, max_tokens, temperature, system, messages):\n",
    "    # rendered_messages = []\n",
    "    # newline2 = '\\n\\n'\n",
    "    # roleprefix = '####################################\\n'\n",
    "    # for msg in messages:\n",
    "    #     text_blocks = []\n",
    "    #     for ct in msg['content']:\n",
    "    #         if ct['type'] != 'text':\n",
    "    #             print('! Warning: ignoring non-text content')\n",
    "    #             continue\n",
    "    #         text_blocks.append(ct['text'])\n",
    "    #     message_content = ''.join(text_blocks)\n",
    "    #     rendered_messages.append(f'{roleprefix}{msg[\"role\"].upper()}: {message_content}')\n",
    "    # rendered = f'{roleprefix}SYSTEM: {system}{newline2}{newline2.join(rendered_messages)}'\n",
    "    # print(rendered)\n",
    "    totalResult = ''\n",
    "    with anthropic_client.messages.stream(\n",
    "        model=model,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        system=system,\n",
    "        messages=messages\n",
    "    ) as stream:\n",
    "        print('Assistant: ', end=\"\", flush=True)\n",
    "        for text in stream.text_stream:\n",
    "            totalResult += text\n",
    "            print(text, end=\"\", flush=True)\n",
    "        print('\\n')\n",
    "    return totalResult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = ''\n",
    "\n",
    "# botreply = claude_stream(\n",
    "#     model=claude_opus,\n",
    "#     max_tokens=4096,\n",
    "#     temperature=0,\n",
    "#     system=system_prompt,\n",
    "#     messages=[\n",
    "#         {\n",
    "#             'role': 'user',\n",
    "#             'content': [\n",
    "#                 {\n",
    "#                     'type': 'text',\n",
    "#                     'text': 'Hello world',\n",
    "#                 }\n",
    "#             ]\n",
    "#         }\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, List, Dict\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    role: Literal['user', 'assistant']\n",
    "    text: str\n",
    "\n",
    "@dataclass\n",
    "class Transcript:\n",
    "    messages: List[Message]\n",
    "\n",
    "    def to_messages(self):\n",
    "        return [{\n",
    "            'role': m.role,\n",
    "            'content': [\n",
    "                {\n",
    "                    'type': 'text',\n",
    "                    'text': m.text\n",
    "                }\n",
    "            ]\n",
    "        } for m in self.messages]\n",
    "\n",
    "def run_anthropic_chat_loop():\n",
    "    transcript = Transcript(messages=[])\n",
    "    while True:\n",
    "        while True:\n",
    "            user_msg = input()\n",
    "            if user_msg == 'exit':\n",
    "                return\n",
    "            elif len(user_msg) > 0:\n",
    "                break\n",
    "        print(f'User: {user_msg}\\n')\n",
    "        transcript.messages.append(Message(role='user', text=user_msg))\n",
    "        botreply = claude_stream(\n",
    "            model=claude_opus,\n",
    "            max_tokens=4096,\n",
    "            temperature=0,\n",
    "            system=system_prompt,\n",
    "            messages=transcript.to_messages(),\n",
    "        )\n",
    "        transcript.messages.append(Message(role='assistant', text=botreply))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: say hi\n",
      "\n",
      "Assistant: Hi there! How can I assist you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_anthropic_chat_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test. This is a test. This is a test. This is a test. This is a test. This is a test. This is a test. This is a test. This is a test. This is a test."
     ]
    }
   ],
   "source": [
    "# Basic OpenAI usage\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=cfg('OPENAI_KEY'))\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say this is a test 10 times\"}],\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in stream:\n",
    "    # print(chunk.choices)\n",
    "    if len(chunk.choices) == 0:\n",
    "        continue\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def mirror(s):\n",
    "    time.sleep(2)\n",
    "    # await asyncio.sleep(2)\n",
    "    return s\n",
    "\n",
    "\n",
    "# res = asyncio.gather(*[mirror(i) for i in range(5)])\n",
    "# print(await res)\n",
    "\n",
    "print(await asyncio.gather(mirror(1), mirror(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message_start\n",
      "content_block_start\n",
      "content_block_delta\n",
      "content_block_delta\n",
      "content_block_delta\n",
      "content_block_delta\n",
      "content_block_delta\n",
      "content_block_delta\n",
      "content_block_delta\n",
      "content_block_delta\n",
      "content_block_delta\n",
      "content_block_delta\n",
      "content_block_delta\n",
      "content_block_delta\n",
      "content_block_delta\n",
      "content_block_delta\n",
      "content_block_delta\n",
      "content_block_stop\n",
      "message_delta\n",
      "message_stop\n"
     ]
    }
   ],
   "source": [
    "from anthropic import AsyncAnthropic\n",
    "\n",
    "client = AsyncAnthropic(api_key=anthropic_key)\n",
    "\n",
    "stream = await client.messages.create(\n",
    "    model=claude_opus,\n",
    "    max_tokens=4096,\n",
    "    temperature=0,\n",
    "    system='',\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Hello, Claude\",\n",
    "        }\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "async for event in stream:\n",
    "    print(event)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
